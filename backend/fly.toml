# fly.toml - Fly.io deployment configuration
# See https://fly.io/docs/reference/configuration/

app = "financial-advisor-backend"
primary_region = "iad"  # US East (Ashburn)

[build]
  dockerfile = "Dockerfile.prod"

[env]
  APP_ENV = "production"
  APP_DEBUG = "false"
  OPENAI_CHAT_MODEL = "gpt-4o-mini"
  OPENAI_EMBEDDING_MODEL = "text-embedding-3-small"
  WORKER_POLL_INTERVAL = "10"
  WORKER_MAX_CONCURRENT = "3"

[http_service]
  internal_port = 8000
  force_https = true
  auto_stop_machines = false
  auto_start_machines = true
  min_machines_running = 1
  processes = ["app"]

  [http_service.concurrency]
    type = "requests"
    soft_limit = 200
    hard_limit = 250

[[services]]
  protocol = "tcp"
  internal_port = 8000
  processes = ["app"]

  [[services.ports]]
    port = 80
    handlers = ["http"]
    force_https = true

  [[services.ports]]
    port = 443
    handlers = ["tls", "http"]

  [services.concurrency]
    type = "connections"
    hard_limit = 25
    soft_limit = 20

  [[services.tcp_checks]]
    interval = "15s"
    timeout = "2s"
    grace_period = "30s"
    restart_limit = 0

  [[services.http_checks]]
    interval = "10s"
    timeout = "2s"
    grace_period = "30s"
    method = "get"
    path = "/health"
    protocol = "http"
    restart_limit = 0
    tls_skip_verify = false

[[vm]]
  cpu_kind = "shared"
  cpus = 1
  memory_mb = 512  # Minimal memory for cost optimization
