# fly.toml - Fly.io deployment configuration
# See https://fly.io/docs/reference/configuration/

app = "financial-advisor-backend"
primary_region = "mia"  # Miami - closest to your region

[build]
  dockerfile = "Dockerfile"

[env]
  APP_NAME = "Financial Advisor AI"
  APP_ENV = "production"
  APP_DEBUG = "false"
  AUTO_CREATE_PGVECTOR_EXTENSION = "false"
  VECTOR_DIMENSION = "1536"
  OPENAI_CHAT_MODEL = "gpt-5-nano"
  OPENAI_EMBEDDING_MODEL = "text-embedding-3-small"
  WORKER_POLL_INTERVAL = "5"
  WORKER_MAX_CONCURRENT = "10"
  WORKER_LOCK_TIMEOUT = "300"

[http_service]
  internal_port = 8000
  force_https = true
  auto_stop_machines = false
  auto_start_machines = true
  min_machines_running = 1
  processes = ["app"]

  [http_service.concurrency]
    type = "requests"
    soft_limit = 200
    hard_limit = 250

[[http_service.checks]]
  interval = "30s"
  timeout = "5s"
  grace_period = "10s"
  method = "GET"
  path = "/health"

[[vm]]
  size = "shared-cpu-1x"
  memory = "512mb"
  cpu_kind = "shared"
  cpus = 1

[deploy]
  strategy = "rolling"
  max_unavailable = 0.5
